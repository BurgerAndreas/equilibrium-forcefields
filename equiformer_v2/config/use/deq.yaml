# @package _global_
# ^^^ this @package directive solves any nesting problem (if this file is included in another folder)

# call:
# scripts/deq_equiformer.py wandb=False ++preset=md17_aspirin_sel2.yaml

defaults:
  # if _self_ is the first entry, compositions will overwrite this config
  # if _self_ is the last entry, this config will overwrite compositions (default)
  # https://hydra.cc/docs/1.3/upgrades/1.0_to_1.1/default_composition_order/
  # - oc20
  - _self_

override_test: 2

model_is_deq: True

model:
  name: deq_equiformer_v2_oc20
  num_layers: 1

  # deq
  z0: "zero"
  # concat or add input injection to node_features (fixed-point estimate)
  cat_injection: False
  norm_injection: prev # None=False, 'one', 'prev'
  path_norm: "none"
  irrep_norm: None 


# passed to torchdeq
deq_kwargs:
  # https://torchdeq.readthedocs.io/en/latest/torchdeq/core.html#torchdeq.core.get_deq
  # 'broyden' anderson newton
  # (str, optional) – The forward solver function. Default 'fixed_point_iter'
  f_solver: 'anderson'
  # (str, optional) – The backward solver function. Default 'fixed_point_iter'.
  b_solver: 'fixed_point_iter'
  # f_tol (float, optional) – The forward pass solver stopping criterion. Default 1e-3.
  f_tol: 1e-3
  # b_tol (float, optional) – The backward pass solver stopping criterion. Default 1e-6.
  b_tol: 1e-6
  # f_max_iter (int, optional) – Maximum number of iterations (NFE) for the forward solver. Default 40.
  f_max_iter: 40
  # b_max_iter (int, optional) – Maximum number of iterations (NFE) for the backward solver. Default 40
  b_max_iter: 40
  # ift (bool, optional) – If true, enable Implicit Differentiation. 
  # IFT=Implicit Function Theorem. Default False.
  ift: False
  # grad (Union[int, list[int], tuple[int]], optional) 
  # Specifies the steps of PhantomGrad. It allows for using multiple values 
  # to represent different gradient steps in the sampled trajectory states. 
  # Default 1.
  grad: 1

  # regularization
  # jac_reg: False
  # jac_loss_weight: 0.0
  # jac_loss_freq: 0.0
  # jac_incremental: 0.0
  # torchdeq.loss.jac_reg(f0, z0, vecs=1, create_graph=True)

output_dir: model/md17/deq_v2/test
#!/bin/bash

# bash or sh
# Node resource configurations
# https://support.vectorinstitute.ai/Vaughan_slurm_changes
#SBATCH --job-name=sd_pokemon_lora
#SBATCH --mem=32G
#SBATCH --cpus-per-task=4
# a40, 48GB, gpu[001-015], gpu[027-056]
# rtx6000, 24GB
#SBATCH --partition=rtx6000
#SBATCH --gres=gpu:1
#SBATCH --qos=normal
#SBATCH --time=16:00:00

# Append is important because otherwise preemption resets the file
#SBATCH --open-mode=append

echo `date`: Job $SLURM_JOB_ID is allocated resource

# the recommendation is to keep erything that defines the workload itself in a separate script
# bash scripts/slurm_lora.sh
echo "Inside slurm_launcher.slrm ($0). received arguments: $@"

# export SCRIPTDIR=/h/burgeran/equilibrium-forcefields/equilibrium-forcefields/train
export SCRIPTDIR=/h/burgeran/equilibrium-forcefields
if [[ $1 == *"test"* ]]; then
    echo "Found test in the filename. Changing the scriptdir to /h/burgeran/equilibrium-forcefields/test"
    export SCRIPTDIR=/h/burgeran/equilibrium-forcefields/tests
fi

# hand over all arguments to the script
echo "Submitting ${SCRIPTDIR}/$@"

# V1
# /h/burgeran/venv10/bin/python ${SCRIPTDIR}/"$@"

# V2 - works!
source /h/burgeran/venv10/bin/activate
/h/burgeran/venv10/bin/python ${SCRIPTDIR}/"$@"

# V3
# /h/burgeran/venv10/bin/accelerate-launch ${SCRIPTDIR}/"$@"

# V4
# source ~/venv10/bin/activate
# python ${SCRIPTDIR}/"$@"
# deactivate

echo `date`: "Job $SLURM_JOB_ID finished running, exit code: $?"

# date=$(date '+%Y-%m-%d')
# archive=$HOME/finished_jobs/$date/$SLURM_JOB_ID
# mkdir -p $archive

# echo archive $archive
# cp ./$SLURM_JOB_ID.out $archive/job.out
# cp ./$SLURM_JOB_ID.err $archive/job.err

# usage: 
# sbatch scripts/slurm_launcher.slrm deq_equiformer.py +machine=vector batch_size=16
